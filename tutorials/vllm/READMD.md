VLLM

llmcompressppor for codestral-mamba

- pip install llmcompressor

-  huggingface-cli download TinyLlama/TinyLlama-1.1B-Chat-v1.0

- python tiny_llama.py


- Reference
    - https://github.com/vllm-project/llm-compressor/