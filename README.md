LLM Recipes

Usage of LLM for Everyday use

- v1
    - Agents : autogen + vllm + gemma
        - [VLLM setup](https://github.com/slabstech/llm-recipes/blob/main/docs/vllm.md) 
    - Agents : autogen + ollama + gemma
        - Setup + Documentation at [docs/2024/agent-code.md](https://github.com/slabstech/llm-recipes/blob/main/docs/2024/agent-code.md) 
        - Code examples at [src/autogen](https://github.com/slabstech/llm-recipes/tree/main/src/autogen)
        - Output from examples at [docs/2024/agent-example-output.md](https://github.com/slabstech/llm-recipes/blob/main/docs/2024/agent-example-output.md)
- v0
    - ChatUI  : ollama + open-webui + mistral-7B + docker
        - Setup + Documentation at [docs/ollama-open-webui.md](https://github.com/slabstech/llm-recipes/blob/main/docs/ollama-open-webui.md)
    - Code CoPilot : vscode + continue + ollama + mistral-7B
        - Setup document at [docs/code-pair.md](https://github.com/slabstech/llm-recipes/blob/main/docs/code-pair.md)