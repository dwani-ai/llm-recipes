{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ee4289-007b-456d-8228-2eadb81f098a",
   "metadata": {},
   "source": [
    "# Function Calling with local model using mistral-inference\n",
    "\n",
    "Function calling allows Mistral models to connect to external tools. By integrating Mistral models with external tools such as user defined functions or APIs, users can easily build applications catering to specific use cases and practical problems. In this guide, for instance, we wrote two functions for tracking payment status and payment date. We can use these two tools to provide answers for payment-related queries.\n",
    "\n",
    "At a glance, there are four steps with function calling:\n",
    "\n",
    "- User: specify tools and query\n",
    "- Model: Generate function arguments if applicable\n",
    "- User: Execute function to obtain tool results\n",
    "- Model: Generate final answer\n",
    "\n",
    "In this guide, we will walk through a simple example to demonstrate how function calling works with Mistral models in these four steps.\n",
    "\n",
    "Before we get started, let’s assume we have a dataframe consisting of payment transactions. When users ask questions about this dataframe, they can use certain tools to answer questions about this data. This is just an example to emulate an external database that the LLM cannot directly access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca82f87-1a09-4a8b-81e8-44df6a72fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas mistral-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc817409-8c86-4764-8ed6-12aceb02d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming we have the following data\n",
    "data = {\n",
    "    'transaction_id': ['T1001', 'T1002', 'T1003', 'T1004', 'T1005'],\n",
    "    'customer_id': ['C001', 'C002', 'C003', 'C002', 'C001'],\n",
    "    'payment_amount': [125.50, 89.99, 120.00, 54.30, 210.20],\n",
    "    'payment_date': ['2021-10-05', '2021-10-06', '2021-10-07', '2021-10-05', '2021-10-08'],\n",
    "    'payment_status': ['Paid', 'Unpaid', 'Paid', 'Paid', 'Pending']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182bb4b-ea8e-4886-a3a5-291c9355d30e",
   "metadata": {},
   "source": [
    "## Step 1. User: specify tools and query\n",
    "\n",
    "### Tools\n",
    "\n",
    "Users can define all the necessary tools for their use cases.\n",
    "\n",
    "- In many cases, we might have multiple tools at our disposal. For example, let’s consider we have two functions as our two tools: `retrieve_payment_status` and `retrieve_payment_date` to retrieve payment status and payment date given transaction ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d7033a-28d6-440e-b6e3-dbb847625a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_payment_status(df: data, transaction_id: str) -> str:\n",
    "    if transaction_id in df.transaction_id.values: \n",
    "        return json.dumps({'status': df[df.transaction_id == transaction_id].payment_status.item()})\n",
    "    return json.dumps({'error': 'transaction id not found.'})\n",
    "\n",
    "def retrieve_payment_date(df: data, transaction_id: str) -> str:\n",
    "    if transaction_id in df.transaction_id.values: \n",
    "        return json.dumps({'date': df[df.transaction_id == transaction_id].payment_date.item()})\n",
    "    return json.dumps({'error': 'transaction id not found.'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986fc53-ae54-49d7-896c-d30254588bb1",
   "metadata": {},
   "source": [
    "- In order for Mistral models to understand the functions, we need to outline the function specifications with a JSON schema. Specifically, we need to describe the type, function name, function description, function parameters, and the required parameter for the function. Since we have two functions here, let’s list two function specifications in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf038c1-648c-44d8-b89a-df08a5e1187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistral_common.protocol.instruct.tool_calls import Function, Tool\n",
    "\n",
    "tools=[\n",
    "        Tool(\n",
    "            function=Function(\n",
    "                name=\"retrieve_payment_status\",\n",
    "                description=\"Get payment status of a transaction\",\n",
    "                parameters={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"transaction_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The transaction id.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"transaction_id\"],\n",
    "                },\n",
    "            )\n",
    "        ),\n",
    "        Tool(\n",
    "            function=Function(\n",
    "                name=\"retrieve_payment_date\",\n",
    "                description=\"Get payment date of a transaction\",\n",
    "                parameters={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"transaction_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The transaction id.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"transaction_id\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0039fa-d43e-472c-8a1c-7bc12e6aaa0a",
   "metadata": {},
   "source": [
    "- Then we organize the two functions into a dictionary where keys represent the function name, and values are the function with the df defined. This allows us to call each function based on its function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382a6359-e12a-4d61-96b5-bc47ee3247fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "names_to_functions = {\n",
    "  'retrieve_payment_status': functools.partial(retrieve_payment_status, df=df),\n",
    "  'retrieve_payment_date': functools.partial(retrieve_payment_date, df=df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa3bbc-ce65-43a0-81ce-0c05836af961",
   "metadata": {},
   "source": [
    "### User query\n",
    "\n",
    "Suppose a user asks the following question: “What’s the status of my transaction?” A standalone LLM would not be able to answer this question, as it needs to query the business logic backend to access the necessary data. But what if we have an exact tool we can use to answer this question? We could potentially provide an answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c983a-148e-4ff3-aee7-68a76af6d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "\n",
    "messages=[UserMessage(content=\"What's the status of my transaction T1003?\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439124dd-ea61-4bba-894d-3d9214af7d0c",
   "metadata": {},
   "source": [
    "## Step 2. Model: Generate function arguments \n",
    "\n",
    "How do Mistral models know about these functions and know which function to use? We provide both the user query and the tools specifications to Mistral models. The goal in this step is not for the Mistral model to run the function directly. It’s to 1) determine the appropriate function to use , 2) identify if there is any essential information missing for a function, and 3) generate necessary arguments for the chosen function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a205e11-f156-41c8-acb5-cba334b68f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistral_inference.model import Transformer\n",
    "from mistral_inference.generate import generate\n",
    "\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450403af-e9fe-4414-b9b7-12865fe5579d",
   "metadata": {},
   "source": [
    "- We specify the location to load the mistral model and tokenizer.  These models are downloaded from [mistral-inference](https://github.com/mistralai/mistral-inference) repo. We have downloaded the mistral 7BInstructv3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444e1838-d620-4a05-a68a-554f28cf5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MistralTokenizer.from_file(\"./mistral_models/7B_instruct/tokenizer.model.v3\")  # change to extracted tok>\n",
    "model = Transformer.from_folder(\"./mistral_models/7B_instruct\")  # change to extracted model dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f8b66a-ce58-4dd1-b9fb-40f80d9112e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_request = ChatCompletionRequest(tools, messages,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d5c1f1-0433-48cc-884e-120df75493b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_chat_completion(completion_request).tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf881d2-89e9-442d-a48a-aa4800b7b179",
   "metadata": {},
   "source": [
    "max_tokens control the output of model as tokens, set it based on required function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdf68b2-a3dd-40a9-83a6-975662493901",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tokens, _ = generate([tokens], model, max_tokens=30, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4ef6c0-f6ea-4c09-8181-efb2c82f5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
    "#remove any blank space from token output\n",
    "result = result.strip()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e72294-eb42-4818-9d67-c897b26ec0ab",
   "metadata": {},
   "source": [
    "## Step 3. User: Execute function to obtain tool results\n",
    "\n",
    "How do we execute the function? Currently, it is the user’s responsibility to execute these functions and the function execution lies on the user side. In the future, we may introduce some helpful functions that can be executed server-side.\n",
    "\n",
    "Let’s extract some useful function information from model response including function_name and function_params. It’s clear here that our Mistral model has chosen to use the function `retrieve_payment_status` with the parameter `transaction_id` set to T1001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e804ace-ab26-4a6c-b3ea-96ab330dc748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function_name:  retrieve_payment_status \n",
      "function_params:  {'transaction_id': 'T1003'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "tool_call = json.loads(result)\n",
    "function_name = tool_call[0][\"name\"]\n",
    "function_params = (tool_call[0][\"arguments\"]) \n",
    "print(\"\\nfunction_name: \", function_name, \"\\nfunction_params: \", function_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f5b003-5a40-4ad6-9b99-bf161063f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\": \"Paid\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_result = names_to_functions[function_name](**function_params)\n",
    "function_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fd1b0-7c27-41a3-ac0b-97fa16630ed3",
   "metadata": {},
   "source": [
    "Setup functions to make REST API call. We take example of pet store from [Swagger Editor](https://editor.swagger.io/)  \n",
    "We download the openapi.json specification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260b178-4c15-4be4-a648-08b7dacedab1",
   "metadata": {},
   "source": [
    "# Function Calling for REST API\n",
    "\n",
    "## Step 1. User: specify tools and query\n",
    "\n",
    "### Tools\n",
    "\n",
    "Users can define all the necessary tools for their use cases.\n",
    "\n",
    "- In many cases, we might have multiple tools at our disposal. For example, let’s consider we have two functions as our two tools: `retrieve_pet_info` and `retreive_user_info` to retrieve pet and user info given `petID` and `username`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570612a-efef-491f-8e18-8df298ce0b6a",
   "metadata": {},
   "source": [
    "Example curl query to get information of a Pet by PetID\n",
    "\n",
    "`\n",
    "curl -X 'GET' \\\n",
    "  'https://petstore3.swagger.io/api/v3/pet/1' \\\n",
    "  -H 'accept: application/json'\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3318df2f-f011-486d-89bc-ec5a6de42fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_pet_info(url: str, petId: int) -> str:\n",
    "    try:\n",
    "        method = 'GET'\n",
    "        headers=None\n",
    "        data=None\n",
    "        url =  url + str(petId)\n",
    "        response = requests.request(method, url, headers=headers, data=data)\n",
    "        # Raise an exception if the response was unsuccessful\n",
    "        response.raise_for_status()\n",
    "        #response = make_api_call('GET', url + str(petId))\n",
    "        if response.ok :\n",
    "            json_response = response.json()\n",
    "            if petId == json_response['id']:\n",
    "                return json_response\n",
    "        return json.dumps({'error': 'Pet id not found.'})\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if response.status_code == 404:\n",
    "            return json.dumps({'error': 'Pet id not found.'})\n",
    "        else:\n",
    "            return json.dumps({'error': 'Error with API.'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7a3a7-cf8e-4143-b583-a64bd46f6ee9",
   "metadata": {},
   "source": [
    "Example curl query to get information of a User by username\n",
    "`\n",
    "curl -X 'GET' \\\n",
    "  'https://petstore3.swagger.io/api/v3/user/user1' \\\n",
    "  -H 'accept: application/json'\n",
    "`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a2bb13e-eaca-4688-b87a-1d13e45c9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_user_info(url: str, username: str) -> str:\n",
    "    try:\n",
    "\n",
    "        url =  url + username\n",
    "        response = requests.get(url)\n",
    "        # Raise an exception if the response was unsuccessful\n",
    "        response.raise_for_status()\n",
    "        if response.ok :\n",
    "            json_response = response.json()\n",
    "            if username == json_response['username']:\n",
    "                return json_response\n",
    "        return json.dumps({'error': 'Username id not found.'})\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if response.status_code == 404:\n",
    "            return json.dumps({'error': 'Username not found.'})\n",
    "        else:\n",
    "            return json.dumps({'error': 'Error with API.'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "17938b1e-0b02-4969-905a-8e88196d0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_functions = {\n",
    "  'retrieve_pet_info': functools.partial(retrieve_pet_info, url='', petId=''),\n",
    "  'retrieve_user_info': functools.partial(retrieve_user_info, url='', username='')  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb6d2f53-d676-4bea-bebf-2d560d6f49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function_name:  retrieve_pet_info \n",
      "function_params:  {'url': 'https://petstore3.swagger.io/api/v3/pet/', 'petId': 1}\n"
     ]
    }
   ],
   "source": [
    "function_name = 'retrieve_pet_info'\n",
    "function_params = {'url':'https://petstore3.swagger.io/api/v3/pet/', 'petId':1}\n",
    "print(\"\\nfunction_name: \", function_name, \"\\nfunction_params: \", function_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "102a1b23-cbb2-49d6-a284-5262f40b6be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'category': {'id': 1, 'name': 'Bears'},\n",
       " 'name': 'Zoe',\n",
       " 'photoUrls': ['string'],\n",
       " 'tags': [{'id': 1, 'name': 'string'}],\n",
       " 'status': 'available'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_result = names_to_functions[function_name](**function_params)\n",
    "function_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "176cecd6-e59c-4936-8553-1e55422a6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function_name:  retrieve_user_info \n",
      "function_params:  {'url': 'https://petstore3.swagger.io/api/v3/user/', 'username': 'user1'}\n"
     ]
    }
   ],
   "source": [
    "function_name = 'retrieve_user_info'\n",
    "function_params = {'url':'https://petstore3.swagger.io/api/v3/user/', 'username':'user1'}\n",
    "print(\"\\nfunction_name: \", function_name, \"\\nfunction_params: \", function_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8bc3c04-3db8-4b47-9e45-7b20b32c1b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'username': 'user1',\n",
       " 'firstName': 'first name 1',\n",
       " 'lastName': 'last name 1',\n",
       " 'email': 'email1@test.com',\n",
       " 'password': 'XXXXXXXXXXX',\n",
       " 'phone': '123-456-7890',\n",
       " 'userStatus': 1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_result = names_to_functions[function_name](**function_params)\n",
    "function_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dd8ba-ff13-4b63-9573-2a795836dcee",
   "metadata": {},
   "source": [
    "TODO - parse open api spec for dynamic tool definition creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e34ed-6be6-4bf0-9999-dde20c31a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade  prance openapi-spec-validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bd29f9c-60c9-41e8-808c-629721a2ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prance\n",
    "\n",
    "def load_openapi_spec(file_path):\n",
    "    \"\"\"\n",
    "    Loads an OpenAPI specification from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the OpenAPI specification file.\n",
    "        \n",
    "    Returns:\n",
    "        The parsed OpenAPI specification object.\n",
    "    \"\"\"\n",
    "    # Parse the OpenAPI specification file\n",
    "    parser = prance.ResolvingParser(file_path, backend='openapi-spec-validator')\n",
    "\n",
    "    #parser = prance.ResolvingParser(file_path)\n",
    "    spec = parser.specification\n",
    "\n",
    "    return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a00a2e3-7108-460a-b3e9-09f290761794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths: ['/pet', '/pet/findByStatus', '/pet/findByTags', '/pet/{petId}', '/pet/{petId}/uploadImage', '/store/inventory', '/store/order', '/store/order/{orderId}', '/user', '/user/createWithList', '/user/login', '/user/logout', '/user/{username}']\n",
      "getPetById\n",
      "Returns a single pet\n",
      "[{'name': 'petId', 'in': 'path', 'description': 'ID of pet to return', 'required': True, 'schema': {'type': 'integer', 'format': 'int64'}}]\n"
     ]
    }
   ],
   "source": [
    "# Load the OpenAPI specification\n",
    "spec = load_openapi_spec('openapi.json')\n",
    "print(f\"Paths: {list(spec['paths'].keys())}\")\n",
    "# Display json for get\n",
    "#spec['paths']['/pet/{petId}']['get']\n",
    "function_name=spec['paths']['/pet/{petId}']['get']['operationId']\n",
    "print(function_name)\n",
    "function_description=spec['paths']['/pet/{petId}']['get']['description']\n",
    "print(function_description)\n",
    "function_parameters=spec['paths']['/pet/{petId}']['get']['parameters']\n",
    "print(function_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64293f6-e148-416f-8993-1065fc255411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
